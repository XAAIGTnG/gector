{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lihao/anaconda3/envs/gec2onnx/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/lihao/anaconda3/envs/gec2onnx/lib/python3.7/site-packages/sklearn/utils/validation.py:37: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  LARGE_SPARSE_SUPPORTED = LooseVersion(scipy_version) >= '0.14.0'\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from gector.gec_model import GecBERTModel\n",
    "from gector.seq2labels_model import Seq2Labels\n",
    "from allennlp.nn import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "roberta_gec = GecBERTModel(vocab_path='data/output_vocabulary/', model_paths=['model/roberta_1_gectorv2.th'], is_ensemble=True)\n",
    "# xlnet_gec = GecBERTModel(vocab_path='data/output_vocabulary/', model_paths=['model/xlnet_0_gectorv2.th'], is_ensemble=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['I', 'want', 'play', 'video', 'games', 'with', 'you'],\n",
       " ['You', 'know', 'I', 'love', 'you'],\n",
       " ['You',\n",
       "  'said',\n",
       "  'that',\n",
       "  'you',\n",
       "  'did',\n",
       "  'not',\n",
       "  'like',\n",
       "  'me',\n",
       "  'before',\n",
       "  'I',\n",
       "  'told',\n",
       "  'you',\n",
       "  'that',\n",
       "  'I',\n",
       "  'love',\n",
       "  'you',\n",
       "  ',',\n",
       "  'so',\n",
       "  'I',\n",
       "  'am',\n",
       "  'very',\n",
       "  'sad',\n",
       "  '.']]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = ['I wants play video games with you'.split(), \n",
    "'You know I loves you'.split(), 'You said that you do not like me before I tell you that I love you so I very sad'.split()]\n",
    "p, i, e = roberta_gec.predict(roberta_gec.preprocess(input))\n",
    "roberta_gec.postprocess_batch(input, p, i, e)\n",
    "# p, i, e = xlnet_gec.predict(xlnet_gec.preprocess(input))\n",
    "# xlnet_gec.postprocess_batch(input, p, i, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class gec(torch.nn.Module):\n",
    "    def __init__(self, model, model_) -> None:\n",
    "        super().__init__()\n",
    "        \n",
    "        self.model = model\n",
    "        self.model_ = model_\n",
    "        \n",
    "    def forward(self, bert, bert_offsets, mask):\n",
    "        token = {\n",
    "            'bert': bert,\n",
    "            'bert-offsets': bert_offsets,\n",
    "            'mask': mask\n",
    "        }\n",
    "        outputs = self.model.forward(token)\n",
    "        return outputs['class_probabilities_labels'], outputs['max_error_probability']\n",
    "        # return self.model_._convert([outputs])\n",
    "\n",
    "model = Seq2Labels(vocab=roberta_gec.vocab,\n",
    "                               text_field_embedder=roberta_gec._get_embbeder('roberta-base', 1),\n",
    "                               confidence=0,\n",
    "                               del_confidence=0,\n",
    "                               )\n",
    "model.load_state_dict(torch.load('model/roberta_1_gectorv2.th'), strict=False)\n",
    "roberta_gec_onnx = gec(model, roberta_gec).to('cuda:0')\n",
    "# xlnet_gec_onnx = gec(model, xlnet_gec).to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bert': tensor([[50265,    38,  1072,   310,   569,   426,    19,    47,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [50265,   370,   216,    38,  6138,    47,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [50265,   370,    26,    14,    47,   109,    45,   101,   162,   137,\n",
      "            38,  1137,    47,    14,    38,   657,    47,    98,    38,   182,\n",
      "          5074]], device='cuda:0'), 'bert-offsets': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0],\n",
      "        [ 0,  1,  2,  3,  4,  5,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0],\n",
      "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "         18, 19, 20]], device='cuda:0'), 'mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      "       device='cuda:0')}\n"
     ]
    }
   ],
   "source": [
    "tokens = util.move_to_device(roberta_gec.preprocess(input)[0].as_tensor_dict(), 0)['tokens']\n",
    "# tokens = util.move_to_device(xlnet_gec.preprocess(input)[0].as_tensor_dict(), 0)['tokens']\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[9.9964e-01, 2.1862e-06, 2.0243e-07,  ..., 1.4559e-10,\n",
       "           4.5591e-05, 2.5049e-16],\n",
       "          [9.9878e-01, 5.4107e-05, 1.4484e-07,  ..., 4.4247e-12,\n",
       "           3.6149e-05, 4.5273e-16],\n",
       "          [1.0072e-02, 5.0254e-04, 3.3500e-05,  ..., 6.9566e-09,\n",
       "           6.4263e-04, 2.0264e-15],\n",
       "          ...,\n",
       "          [9.9964e-01, 2.1862e-06, 2.0243e-07,  ..., 1.4559e-10,\n",
       "           4.5591e-05, 2.5049e-16],\n",
       "          [9.9964e-01, 2.1862e-06, 2.0243e-07,  ..., 1.4559e-10,\n",
       "           4.5591e-05, 2.5049e-16],\n",
       "          [9.9964e-01, 2.1862e-06, 2.0243e-07,  ..., 1.4559e-10,\n",
       "           4.5591e-05, 2.5049e-16]],\n",
       " \n",
       "         [[9.9840e-01, 3.8396e-06, 2.4193e-07,  ..., 4.3083e-09,\n",
       "           1.6794e-04, 2.4708e-15],\n",
       "          [9.9802e-01, 2.9587e-04, 4.1409e-07,  ..., 7.7475e-11,\n",
       "           4.6562e-05, 9.4058e-16],\n",
       "          [9.8774e-01, 2.3780e-04, 1.3869e-04,  ..., 6.0532e-10,\n",
       "           2.6357e-04, 1.2621e-15],\n",
       "          ...,\n",
       "          [9.9840e-01, 3.8396e-06, 2.4193e-07,  ..., 4.3083e-09,\n",
       "           1.6794e-04, 2.4708e-15],\n",
       "          [9.9840e-01, 3.8396e-06, 2.4193e-07,  ..., 4.3083e-09,\n",
       "           1.6794e-04, 2.4708e-15],\n",
       "          [9.9840e-01, 3.8396e-06, 2.4193e-07,  ..., 4.3083e-09,\n",
       "           1.6794e-04, 2.4708e-15]],\n",
       " \n",
       "         [[9.9787e-01, 9.4160e-06, 4.5468e-07,  ..., 9.8518e-09,\n",
       "           1.4210e-04, 4.9067e-15],\n",
       "          [9.9265e-01, 5.1498e-04, 4.4318e-07,  ..., 2.9211e-10,\n",
       "           1.7920e-04, 9.5111e-16],\n",
       "          [9.5802e-01, 4.9831e-04, 1.4054e-05,  ..., 2.9038e-09,\n",
       "           5.8705e-04, 2.1690e-15],\n",
       "          ...,\n",
       "          [4.6541e-02, 5.2717e-03, 6.6833e-05,  ..., 3.9424e-09,\n",
       "           5.0437e-04, 1.5414e-14],\n",
       "          [9.9337e-01, 4.3537e-04, 2.1948e-04,  ..., 2.6527e-09,\n",
       "           3.8803e-04, 5.5708e-15],\n",
       "          [2.3800e-01, 1.8000e-03, 9.6194e-04,  ..., 2.1798e-08,\n",
       "           1.1013e-03, 2.2163e-14]]], device='cuda:0',\n",
       "        grad_fn=<AsStridedBackward0>),\n",
       " tensor([0.9844, 0.9355, 0.9457], device='cuda:0', grad_fn=<MaxBackward0>))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roberta_gec_onnx(tokens['bert'], tokens['bert-offsets'], tokens['mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_names = ['bert', 'bert-offsets', 'mask']\n",
    "# output_names = ['probs', 'idx', 'error_probs']\n",
    "# dynamic_axes = {\n",
    "#     'bert': {0: 'batch_0', 1: 'sequence_0'},\n",
    "#     'bert-offsets': {0: 'batch_1', 1: 'sequence_1'},\n",
    "#     'mask': {0: 'batch_2', 1: 'sequence_2'},\n",
    "#     'probs': {0: 'batch_3', 1: 'sequence_3'},\n",
    "#     'idx': {0: 'batch_4', 1: 'sequence_4'},\n",
    "#     'error_probs': {0: 'batch_5', 1: 'sequence_5'}\n",
    "# }\n",
    "output_names = ['class_probabilities_labels', 'max_error_probability']\n",
    "dynamic_axes = {\n",
    "    'bert': {0: 'batch_0', 1: 'sequence_0'},\n",
    "    'bert-offsets': {0: 'batch_1', 1: 'sequence_1'},\n",
    "    'mask': {0: 'batch_2', 1: 'sequence_2'},\n",
    "    'class_probabilities_labels': {0: 'batch_3', 1: 'sequence_3'},\n",
    "    'max_error_probability': {0: 'batch_4'},\n",
    "    \n",
    "}\n",
    "\n",
    "torch.onnx.export(roberta_gec_onnx, (tokens['bert'], tokens['bert-offsets'], tokens['mask']), \"onnx/roberta-base-old.onnx\",\n",
    "                    input_names=input_names, output_names=output_names, dynamic_axes=dynamic_axes, \n",
    "                    opset_version=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime\n",
    "import numpy as np\n",
    "\n",
    "bert = tokens['bert'].cpu().numpy()\n",
    "bert_offsets = tokens['bert-offsets'].cpu().numpy()\n",
    "mask = tokens['mask'].cpu().numpy()\n",
    "\n",
    "x_onnx = onnxruntime.InferenceSession('onnx/roberta-base-old.onnx', providers=['CUDAExecutionProvider', 'CPUExecutionProvider'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[9.9963760e-01, 2.1861717e-06, 2.0242754e-07, ...,\n",
       "          1.4558639e-10, 4.5591009e-05, 2.5048564e-16],\n",
       "         [9.9877530e-01, 5.4107371e-05, 1.4484240e-07, ...,\n",
       "          4.4247331e-12, 3.6149275e-05, 4.5273212e-16],\n",
       "         [1.0071833e-02, 5.0253852e-04, 3.3500317e-05, ...,\n",
       "          6.9565953e-09, 6.4262724e-04, 2.0263830e-15],\n",
       "         ...,\n",
       "         [9.9963760e-01, 2.1861717e-06, 2.0242754e-07, ...,\n",
       "          1.4558639e-10, 4.5591009e-05, 2.5048564e-16],\n",
       "         [9.9963760e-01, 2.1861717e-06, 2.0242754e-07, ...,\n",
       "          1.4558639e-10, 4.5591009e-05, 2.5048564e-16],\n",
       "         [9.9963760e-01, 2.1861717e-06, 2.0242754e-07, ...,\n",
       "          1.4558639e-10, 4.5591009e-05, 2.5048564e-16]],\n",
       " \n",
       "        [[9.9839586e-01, 3.8395838e-06, 2.4193085e-07, ...,\n",
       "          4.3083128e-09, 1.6794422e-04, 2.4707896e-15],\n",
       "         [9.9801528e-01, 2.9587277e-04, 4.1409226e-07, ...,\n",
       "          7.7474978e-11, 4.6561909e-05, 9.4057556e-16],\n",
       "         [9.8774081e-01, 2.3779625e-04, 1.3869278e-04, ...,\n",
       "          6.0531663e-10, 2.6357063e-04, 1.2621499e-15],\n",
       "         ...,\n",
       "         [9.9839586e-01, 3.8395838e-06, 2.4193085e-07, ...,\n",
       "          4.3083128e-09, 1.6794422e-04, 2.4707896e-15],\n",
       "         [9.9839610e-01, 3.8395847e-06, 2.4193091e-07, ...,\n",
       "          4.3083137e-09, 1.6794426e-04, 2.4707902e-15],\n",
       "         [9.9839586e-01, 3.8395838e-06, 2.4193085e-07, ...,\n",
       "          4.3083128e-09, 1.6794422e-04, 2.4707896e-15]],\n",
       " \n",
       "        [[9.9786633e-01, 9.4160305e-06, 4.5467792e-07, ...,\n",
       "          9.8518198e-09, 1.4210212e-04, 4.9067263e-15],\n",
       "         [9.9264914e-01, 5.1498099e-04, 4.4318330e-07, ...,\n",
       "          2.9211125e-10, 1.7919645e-04, 9.5111011e-16],\n",
       "         [9.5802385e-01, 4.9831398e-04, 1.4053748e-05, ...,\n",
       "          2.9037841e-09, 5.8705243e-04, 2.1690193e-15],\n",
       "         ...,\n",
       "         [4.6541367e-02, 5.2717309e-03, 6.6832494e-05, ...,\n",
       "          3.9424171e-09, 5.0436816e-04, 1.5414500e-14],\n",
       "         [9.9337220e-01, 4.3537430e-04, 2.1948229e-04, ...,\n",
       "          2.6527169e-09, 3.8803116e-04, 5.5708705e-15],\n",
       "         [2.3800015e-01, 1.7999988e-03, 9.6193445e-04, ...,\n",
       "          2.1797801e-08, 1.1013082e-03, 2.2162421e-14]]], dtype=float32),\n",
       " array([0.9843807 , 0.93547416, 0.94565547], dtype=float32)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_onnx.run(\n",
    "    None,\n",
    "    input_feed={\n",
    "        'bert': bert,\n",
    "        'bert-offsets': bert_offsets,\n",
    "        'mask': mask\n",
    "    }\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('gec2onnx': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a6de3605b08ffe14115dc29797642afe911ececa6fe25ccfb3e91ff7cfe9ebcd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
